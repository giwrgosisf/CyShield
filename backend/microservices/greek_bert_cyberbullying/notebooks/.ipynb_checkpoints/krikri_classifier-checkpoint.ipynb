{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mesv0IP-ktmt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp2zuDlWlD_A"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
    "!pip install unsloth\n",
    "# Get latest Unsloth\n",
    "!pip install --upgrade --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VF9E7XAGpfiR"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y torch bitsandbytes triton\n",
    "# !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 \\\n",
    "#     --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install triton bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73LRAtRMiCD0"
   },
   "outputs": [],
   "source": [
    "class KriKriTeacher:\n",
    "\n",
    "  def __init__(self):\n",
    "    from unsloth import FastLanguageModel\n",
    "    print(\"Loading Llama-Krikri-8B-Instruct model...\")\n",
    "    self.model, self.tokenizer = FastLanguageModel.from_pretrained(model_name=\"ilsp/Llama-Krikri-8B-Instruct\",max_seq_length=8192,load_in_4bit = True)\n",
    "\n",
    "    from transformers import TextStreamer\n",
    "    from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "    self.tokenizer = get_chat_template(\n",
    "        self.tokenizer,\n",
    "        chat_template = \"llama-3.1\",\n",
    "    )\n",
    "    FastLanguageModel.for_inference(self.model)\n",
    "\n",
    "    self.prompt_template = \"\"\"\n",
    "    Αναλύεις μηνύματα και τα κατηγοριοποιείς ως BULLY ή NON_BULLY.\n",
    "\n",
    "    Ένα μήνυμα θεωρείται cyberbullying (BULLY) όταν περιλαμβάνει:\n",
    "    1) Άμεσες απειλές, επιθέσεις, προσβολές ή παρενόχληση\n",
    "    2) Απόπειρες αποκλεισμού ή κοινωνικής απομόνωσης\n",
    "    3) Πρόθεση να βλάψει ή να ταπεινώσει\n",
    "    4) Διάδοση φημών ή ψευδών πληροφοριών\n",
    "    5) Bodyshaming ή επιθέσεις με βάση την εμφάνιση\n",
    "    6) Παρενόχληση με βάση την ταυτότητα (φυλή, θρησκεία, σεξουαλικότητα κ.λπ.)\n",
    "    7) Επίμονη ανεπιθύμητη επαφή ή συμπεριφορά καταδίωξης\n",
    "    8) Ενθάρρυνση αυτοτραυματισμού ή αυτοκτονίας\n",
    "    9) Κοινοποίηση ντροπιαστικού περιεχομένου χωρίς συγκατάθεση\n",
    "    10) Χρήση ύβρεων ή υποτιμητικής γλώσσας\n",
    "\n",
    "    Εξέτασε το πλαίσιο, την πρόθεση και τη σοβαρότητα. Κάποια παιχνιδιάρικα πειράγματα μεταξύ φίλων μπορεί να μην αποτελούν διαδικτυακό εκφοβισμό.\n",
    "    Θα απαντάς Ναι αν το μήνυμα θεωρείται cyberbullying ή Οχι αν το μήνυμα ΔΕΝ θεωρείται cyberbullying.\n",
    "\n",
    "    Απάντησε ΜΟΝΟ με μία λέξη: Ναι ή Οχι\n",
    "\n",
    "    Μήνυμα: \"{text}\"\n",
    "    Απάντηση:\"\"\"\n",
    "\n",
    "  def preprocess_text(self, text: str) -> str:\n",
    "    \"\"\"Preprocess texts for consistent handling\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "      return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    # Remove @USER mentions\n",
    "    text = re.sub(r'@USER\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'@\\w+', '[MENTION]', text)\n",
    "\n",
    "    text = re.sub(r'[!]{3,}', '!!!', text)\n",
    "    text = re.sub(r'[?]{3,}', '???', text)\n",
    "    text = re.sub(r'[.]{3,}', '...', text)\n",
    "\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    if len(text.strip()) < 3:\n",
    "      return \"\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "  def classify_single_message(self, text: str, temperature: float = 0.0) -> str:\n",
    "    \"\"\"Classify a single message using KriKri\"\"\"\n",
    "    text = self.preprocess_text(text)\n",
    "\n",
    "    # Format the prompt\n",
    "    formatted_prompt = self.prompt_template.format(text=text)\n",
    "\n",
    "    # Create chat format\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Είσαι ειδικός στον εντοπισμό του cyberbullying στις ψηφιακές συνομιλίες. \"},\n",
    "     {\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    input_text = self.tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    # Tokenize and generate\n",
    "    inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = self.model.generate(\n",
    "          **inputs,\n",
    "          max_new_tokens=4,  #  Nai h Oxi\n",
    "          temperature=temperature,\n",
    "          do_sample=temperature > 0,\n",
    "          pad_token_id= self.tokenizer.eos_token_id,\n",
    "          repetition_penalty=1.1\n",
    "          )\n",
    "\n",
    "    # Decode response\n",
    "    response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "  def normalize_greek_response(self, response: str) -> str:\n",
    "    normalized = response.strip().lower()\n",
    "    nai_variations = ['ναι', 'nai']\n",
    "    oxi_variations = ['όχι', 'οχι', 'oxι', 'oxi', 'ochi']\n",
    "    if any(var in normalized for var in nai_variations):\n",
    "      return 'BULLY'\n",
    "    elif any(var in normalized for var in oxi_variations):\n",
    "      return 'NON_BULLY'\n",
    "    else:\n",
    "          first_word = normalized.split()[0] if normalized.split() else \"\"\n",
    "          if any(first_word.startswith(var[:2]) for var in nai_variations):\n",
    "            return 'BULLY'\n",
    "          elif any(first_word.startswith(var[:2]) for var in oxi_variations):\n",
    "            return 'NON_BULLY'\n",
    "          else:\n",
    "            print(f\"Warning: Unexpected response format: '{response}'\")\n",
    "            return 'NON_BULLY'  # Conservative default\n",
    "\n",
    "\n",
    "\n",
    "  def calculate_soft_labels(self, text: str, n_samples: int = 7) -> tuple[list[float], float]:\n",
    "    \"\"\"\n",
    "    Return soft probabilities [p_bully, p_non_bully] and confidence score.\n",
    "    Uses self-consistency with multiple samples.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    raw_responses = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "      raw_pred = self.classify_single_message(text, temperature=0.2)\n",
    "      normalized_pred = self.normalize_greek_response(raw_pred)\n",
    "      predictions.append(normalized_pred)\n",
    "      raw_responses.append(raw_pred)\n",
    "\n",
    "    pred_counts = Counter(predictions)\n",
    "\n",
    "    total = len(predictions)\n",
    "    prob_bully = pred_counts.get('BULLY', 0) / total\n",
    "    prob_non_bully = pred_counts.get('NON_BULLY', 0) / total\n",
    "\n",
    "    if (prob_bully + prob_non_bully == 0):\n",
    "      # If no valid predictions, default to non-bullying\n",
    "      prob_bully, prob_non_bully = 0.1, 0.9\n",
    "    elif prob_bully + prob_non_bully < 1.0:\n",
    "      # If they sum to something less than 1 (e.g. .4 + .5 = .9), normalize\n",
    "      total_valid = prob_bully + prob_non_bully\n",
    "      if total_valid > 0:\n",
    "        prob_bully /= total_valid\n",
    "        prob_non_bully /= total_valid\n",
    "      else:\n",
    "        prob_bully, prob_non_bully = 0.1, 0.9\n",
    "\n",
    "    majority = 'BULLY' if prob_bully > prob_non_bully else 'NON_BULLY'\n",
    "    confidence = pred_counts.get(majority, 0) / total\n",
    "\n",
    "    return [prob_bully, prob_non_bully], confidence\n",
    "\n",
    "\n",
    "  def process_dataset(self, df: pd.DataFrame,text_column: str = 'text',label_column: str = 'label',confidence_threshold: float = 0.3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process DataFrame of messages, returning filtered results with soft labels.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(f\"Processing {len(df)} messages...\")\n",
    "    print(f\"Mode: Using hand labels as ground truth\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "      text = row[text_column]\n",
    "      hand_label = row[label_column] if label_column in df.columns else None\n",
    "\n",
    "      processed_text = self.preprocess_text(text)\n",
    "      if not processed_text:\n",
    "        print(f\"Skipping empty text at row {idx}\")\n",
    "        continue\n",
    "\n",
    "      # Get soft labels and confidence from LLM\n",
    "      soft_probs, confidence = self.calculate_soft_labels(processed_text)\n",
    "      llm_hard_label = 1 if soft_probs[0] > soft_probs[1] else 0\n",
    "\n",
    "      if hand_label is not None:\n",
    "      # Use hand-annotated labels as ground truth\n",
    "      # But keep LLM soft probabilities for knowledge distillation\n",
    "        result = {\n",
    "            'text': processed_text,\n",
    "            'text_original': text,\n",
    "            'label_hard': int(hand_label),  # Ground truth from annotation\n",
    "            'p_teacher': soft_probs,        # Soft probs from LLM teacher\n",
    "            'confidence': confidence,       # LLM confidence\n",
    "            'llm_label': llm_hard_label,    # LLM prediction\n",
    "            'agreement': int(hand_label) == llm_hard_label\n",
    "            }\n",
    "      else:\n",
    "        result = ''\n",
    "\n",
    "      results.append(result)\n",
    "\n",
    "      if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(df)} messages\")\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Filter by confidence threshold\n",
    "    print(f\"Before filtering: {len(result_df)} samples\")\n",
    "    filtered_df = result_df[result_df['confidence'] >= confidence_threshold].copy()\n",
    "    print(f\"After confidence filtering (>= {confidence_threshold}): {len(filtered_df)} samples\")\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "  def save_distillation_dataset(self, df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"Save the processed dataset for knowledge distillation\"\"\"\n",
    "    distillation_data = []\n",
    "    for _, row in df.iterrows():\n",
    "      distillation_data.append({\n",
    "          'text': row['text'],\n",
    "          'text_original': row['text_original'],\n",
    "          'label_hard': int(row['label_hard']),\n",
    "          'p_teacher': row['p_teacher'],\n",
    "          'confidence': float(row['confidence']),\n",
    "          'llm_label': int(row['llm_label']),           # LLM prediction\n",
    "          'agreement': bool(row['agreement']),\n",
    "          })\n",
    "\n",
    "    try:\n",
    "      from google.colab import drive\n",
    "      import os\n",
    "\n",
    "      if not os.path.exists('/content/drive'):\n",
    "        print(\"Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "      else:\n",
    "        print(\"Google Drive already mounted\")\n",
    "\n",
    "      drive_dir = '/content/drive/MyDrive/cyshield'\n",
    "      os.makedirs(drive_dir, exist_ok=True)\n",
    "\n",
    "      json_path = f\"{drive_dir}/{output_path}\"\n",
    "      csv_path = json_path.replace('.json', '.csv')\n",
    "\n",
    "    except ImportError:\n",
    "      print(\"Saving locally\")\n",
    "      json_path = output_path\n",
    "      csv_path = output_path.replace('.json', '.csv')\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "      json.dump(distillation_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(distillation_data)} samples\")\n",
    "\n",
    "    csv_path = output_path.replace('.json', '.csv')\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"Also saved as CSV: {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVmIOm-0QqFB"
   },
   "outputs": [],
   "source": [
    "def load_and_process_dataset(csv_path: str, text_col: str = 'text', label_col: str = 'label', confidence_threshold: float = 0.3):\n",
    "  print(f\"Loading dataset from {csv_path}\")\n",
    "  df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "\n",
    "  print(f\"Dataset shape: {df.shape}\")\n",
    "  has_hand_labels = label_col in df.columns\n",
    "  if has_hand_labels:\n",
    "    hand_label_dist = df[label_col].value_counts()\n",
    "    print(f\"Hand-labeled distribution: {dict(hand_label_dist)}\")\n",
    "\n",
    "  teacher = KriKriTeacher()\n",
    "\n",
    "  processed_df = teacher.process_dataset(df, text_column=text_col, label_column=label_col,confidence_threshold=confidence_threshold)\n",
    "\n",
    "  output_path = csv_path.replace('.csv', f'_teacher_labels.json')\n",
    "  teacher.save_distillation_dataset(processed_df, output_path)\n",
    "\n",
    "  print(\"\\n=== FINAL STATISTICS ===\")\n",
    "  print(f\"Total processed samples: {len(processed_df)}\")\n",
    "  print(f\"Average LLM confidence: {processed_df['confidence'].mean():.3f}\")\n",
    "  print(f\"Final label distribution: {processed_df['label_hard'].value_counts().to_dict()}\")\n",
    "\n",
    "  if has_hand_labels and 'agreement' in processed_df.columns:\n",
    "    overall_agreement = processed_df['agreement'].mean()\n",
    "    print(f\"Overall LLM-Human Agreement: {overall_agreement:.3f}\")\n",
    "\n",
    "    disagreements = processed_df[~processed_df['agreement']]\n",
    "    if len(disagreements) > 0:\n",
    "      print(f\"Disagreements: {len(disagreements)} samples\")\n",
    "      print(\"Sample disagreements:\")\n",
    "      for idx, row in disagreements.head(3).iterrows():\n",
    "        print(f\"  Text: '{row['text'][:100]}...'\")\n",
    "        print(f\"  Human: {row['label_hard']}, LLM: {row['llm_label']}, Confidence: {row['confidence']:.2f}\")\n",
    "\n",
    "  return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f72ef9941838432aadaf325f36ff15d4",
      "ca2324ead1924b4da4ae7a6c6c31b378",
      "4ff6dafe826641d7a9b3e48793e01e75",
      "b5f835bcc5d64be1a2f957051357430c",
      "b7a494c6133a4c559e0c36b436406aa9",
      "c0687da42aac43f893a627eff6ff9cfc",
      "a3178db6b12f4656b5dbb199b4deacbc",
      "cf24104e2cab4274821619616f09140d",
      "5454372dae334795a92f98a51a96a741",
      "5a26c5a9f05e4feea878ece2739cb248",
      "0b0951d946a04d85acc12b281856dfa9"
     ]
    },
    "id": "C0zpVts4dMv1",
    "outputId": "64673475-9c2a-42f5-b552-66d7ae199419"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "csv_file_path = '/content/drive/MyDrive/cyshield/combined.csv'\n",
    "\n",
    "processed_data = load_and_process_dataset(\n",
    "    csv_path=csv_file_path,\n",
    "    text_col='text',\n",
    "    label_col='label',\n",
    "    confidence_threshold=0.15\n",
    "    )\n",
    "\n",
    "print(\"Teacher labeling complete\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b0951d946a04d85acc12b281856dfa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ff6dafe826641d7a9b3e48793e01e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf24104e2cab4274821619616f09140d",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5454372dae334795a92f98a51a96a741",
      "value": 4
     }
    },
    "5454372dae334795a92f98a51a96a741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a26c5a9f05e4feea878ece2739cb248": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3178db6b12f4656b5dbb199b4deacbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5f835bcc5d64be1a2f957051357430c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a26c5a9f05e4feea878ece2739cb248",
      "placeholder": "​",
      "style": "IPY_MODEL_0b0951d946a04d85acc12b281856dfa9",
      "value": " 4/4 [00:18&lt;00:00,  3.91s/it]"
     }
    },
    "b7a494c6133a4c559e0c36b436406aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0687da42aac43f893a627eff6ff9cfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca2324ead1924b4da4ae7a6c6c31b378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0687da42aac43f893a627eff6ff9cfc",
      "placeholder": "​",
      "style": "IPY_MODEL_a3178db6b12f4656b5dbb199b4deacbc",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "cf24104e2cab4274821619616f09140d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f72ef9941838432aadaf325f36ff15d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca2324ead1924b4da4ae7a6c6c31b378",
       "IPY_MODEL_4ff6dafe826641d7a9b3e48793e01e75",
       "IPY_MODEL_b5f835bcc5d64be1a2f957051357430c"
      ],
      "layout": "IPY_MODEL_b7a494c6133a4c559e0c36b436406aa9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
